{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hello_world.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAj9Cby53PVqK6nbBc+KS5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudhood/flair/blob/main/notebooks/hello_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0sjgHWcymFV"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade flair torch sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "S0d7Uuzs2YZf",
        "outputId": "534dc20a-853a-499f-e30f-d350128a6b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show flair"
      ],
      "metadata": {
        "id": "SheYAfQRyqtN",
        "outputId": "23d175db-9c91-433d-aaf8-58ceac421790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: flair\n",
            "Version: 0.11.3\n",
            "Summary: A very simple framework for state-of-the-art NLP\n",
            "Home-page: https://github.com/flairNLP/flair\n",
            "Author: Alan Akbik\n",
            "Author-email: alan.akbik@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: gensim, scikit-learn, lxml, janome, hyperopt, torch, konoha, conllu, deprecated, bpemb, more-itertools, segtok, regex, wikipedia-api, tabulate, matplotlib, huggingface-hub, sqlitedict, ftfy, mpld3, python-dateutil, sentencepiece, transformers, langdetect, gdown, tqdm, pptree\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "from flair.tokenization import SpaceTokenizer, TokenizerWrapper"
      ],
      "metadata": {
        "id": "zopUGgD60Mzl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"a set of words that is complete in itself, typically containing a subject and predicate, conveying a statement, question, exclamation, or command, and consisting of a main clause and sometimes one or more subordinate clauses\""
      ],
      "metadata": {
        "id": "URCs8K6N09L0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = Sentence(txt)\n",
        "print(sentence, len(sentence))"
      ],
      "metadata": {
        "id": "GP1_Gu6o0oG7",
        "outputId": "049b3a88-b3ff-46ec-8f3c-2441f55832ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \"a set of words that is complete in itself , typically containing a subject and predicate , conveying a statement , question , exclamation , or command , and consisting of a main clause and sometimes one or more subordinate clauses\" 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SpaceTokenizer()\n",
        "s = Sentence(txt, use_tokenizer=tokenizer)\n",
        "\n",
        "# getting the string representation using magic method __str__ \n",
        "print(s, len(s))"
      ],
      "metadata": {
        "id": "Sy3l1gu406Sf",
        "outputId": "9b75c0ed-a87e-49a6-e54b-9e9837992c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \"a set of words that is complete in itself, typically containing a subject and predicate, conveying a statement, question, exclamation, or command, and consisting of a main clause and sometimes one or more subordinate clauses\" 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in sentence:\n",
        "  print(token)"
      ],
      "metadata": {
        "id": "IpoUa6bP08I3",
        "outputId": "5a9bd4b6-3139-46fe-e8e1-6e48659e95a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"a\"\n",
            "Token[1]: \"set\"\n",
            "Token[2]: \"of\"\n",
            "Token[3]: \"words\"\n",
            "Token[4]: \"that\"\n",
            "Token[5]: \"is\"\n",
            "Token[6]: \"complete\"\n",
            "Token[7]: \"in\"\n",
            "Token[8]: \"itself\"\n",
            "Token[9]: \",\"\n",
            "Token[10]: \"typically\"\n",
            "Token[11]: \"containing\"\n",
            "Token[12]: \"a\"\n",
            "Token[13]: \"subject\"\n",
            "Token[14]: \"and\"\n",
            "Token[15]: \"predicate\"\n",
            "Token[16]: \",\"\n",
            "Token[17]: \"conveying\"\n",
            "Token[18]: \"a\"\n",
            "Token[19]: \"statement\"\n",
            "Token[20]: \",\"\n",
            "Token[21]: \"question\"\n",
            "Token[22]: \",\"\n",
            "Token[23]: \"exclamation\"\n",
            "Token[24]: \",\"\n",
            "Token[25]: \"or\"\n",
            "Token[26]: \"command\"\n",
            "Token[27]: \",\"\n",
            "Token[28]: \"and\"\n",
            "Token[29]: \"consisting\"\n",
            "Token[30]: \"of\"\n",
            "Token[31]: \"a\"\n",
            "Token[32]: \"main\"\n",
            "Token[33]: \"clause\"\n",
            "Token[34]: \"and\"\n",
            "Token[35]: \"sometimes\"\n",
            "Token[36]: \"one\"\n",
            "Token[37]: \"or\"\n",
            "Token[38]: \"more\"\n",
            "Token[39]: \"subordinate\"\n",
            "Token[40]: \"clauses\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_tokenizer = TokenizerWrapper(lambda _: list(_))"
      ],
      "metadata": {
        "id": "ZZ5-NPGK1Kr8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = Sentence(txt, use_tokenizer=char_tokenizer)\n",
        "\n",
        "for token in sentence:\n",
        "    print(token)"
      ],
      "metadata": {
        "id": "XZg-YnpP1QNN",
        "outputId": "4c6025d2-54ab-4f6a-9ed0-6fc546c80654",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"a\"\n",
            "Token[1]: \" \"\n",
            "Token[2]: \"s\"\n",
            "Token[3]: \"e\"\n",
            "Token[4]: \"t\"\n",
            "Token[5]: \" \"\n",
            "Token[6]: \"o\"\n",
            "Token[7]: \"f\"\n",
            "Token[8]: \" \"\n",
            "Token[9]: \"w\"\n",
            "Token[10]: \"o\"\n",
            "Token[11]: \"r\"\n",
            "Token[12]: \"d\"\n",
            "Token[13]: \"s\"\n",
            "Token[14]: \" \"\n",
            "Token[15]: \"t\"\n",
            "Token[16]: \"h\"\n",
            "Token[17]: \"a\"\n",
            "Token[18]: \"t\"\n",
            "Token[19]: \" \"\n",
            "Token[20]: \"i\"\n",
            "Token[21]: \"s\"\n",
            "Token[22]: \" \"\n",
            "Token[23]: \"c\"\n",
            "Token[24]: \"o\"\n",
            "Token[25]: \"m\"\n",
            "Token[26]: \"p\"\n",
            "Token[27]: \"l\"\n",
            "Token[28]: \"e\"\n",
            "Token[29]: \"t\"\n",
            "Token[30]: \"e\"\n",
            "Token[31]: \" \"\n",
            "Token[32]: \"i\"\n",
            "Token[33]: \"n\"\n",
            "Token[34]: \" \"\n",
            "Token[35]: \"i\"\n",
            "Token[36]: \"t\"\n",
            "Token[37]: \"s\"\n",
            "Token[38]: \"e\"\n",
            "Token[39]: \"l\"\n",
            "Token[40]: \"f\"\n",
            "Token[41]: \",\"\n",
            "Token[42]: \" \"\n",
            "Token[43]: \"t\"\n",
            "Token[44]: \"y\"\n",
            "Token[45]: \"p\"\n",
            "Token[46]: \"i\"\n",
            "Token[47]: \"c\"\n",
            "Token[48]: \"a\"\n",
            "Token[49]: \"l\"\n",
            "Token[50]: \"l\"\n",
            "Token[51]: \"y\"\n",
            "Token[52]: \" \"\n",
            "Token[53]: \"c\"\n",
            "Token[54]: \"o\"\n",
            "Token[55]: \"n\"\n",
            "Token[56]: \"t\"\n",
            "Token[57]: \"a\"\n",
            "Token[58]: \"i\"\n",
            "Token[59]: \"n\"\n",
            "Token[60]: \"i\"\n",
            "Token[61]: \"n\"\n",
            "Token[62]: \"g\"\n",
            "Token[63]: \" \"\n",
            "Token[64]: \"a\"\n",
            "Token[65]: \" \"\n",
            "Token[66]: \"s\"\n",
            "Token[67]: \"u\"\n",
            "Token[68]: \"b\"\n",
            "Token[69]: \"j\"\n",
            "Token[70]: \"e\"\n",
            "Token[71]: \"c\"\n",
            "Token[72]: \"t\"\n",
            "Token[73]: \" \"\n",
            "Token[74]: \"a\"\n",
            "Token[75]: \"n\"\n",
            "Token[76]: \"d\"\n",
            "Token[77]: \" \"\n",
            "Token[78]: \"p\"\n",
            "Token[79]: \"r\"\n",
            "Token[80]: \"e\"\n",
            "Token[81]: \"d\"\n",
            "Token[82]: \"i\"\n",
            "Token[83]: \"c\"\n",
            "Token[84]: \"a\"\n",
            "Token[85]: \"t\"\n",
            "Token[86]: \"e\"\n",
            "Token[87]: \",\"\n",
            "Token[88]: \" \"\n",
            "Token[89]: \"c\"\n",
            "Token[90]: \"o\"\n",
            "Token[91]: \"n\"\n",
            "Token[92]: \"v\"\n",
            "Token[93]: \"e\"\n",
            "Token[94]: \"y\"\n",
            "Token[95]: \"i\"\n",
            "Token[96]: \"n\"\n",
            "Token[97]: \"g\"\n",
            "Token[98]: \" \"\n",
            "Token[99]: \"a\"\n",
            "Token[100]: \" \"\n",
            "Token[101]: \"s\"\n",
            "Token[102]: \"t\"\n",
            "Token[103]: \"a\"\n",
            "Token[104]: \"t\"\n",
            "Token[105]: \"e\"\n",
            "Token[106]: \"m\"\n",
            "Token[107]: \"e\"\n",
            "Token[108]: \"n\"\n",
            "Token[109]: \"t\"\n",
            "Token[110]: \",\"\n",
            "Token[111]: \" \"\n",
            "Token[112]: \"q\"\n",
            "Token[113]: \"u\"\n",
            "Token[114]: \"e\"\n",
            "Token[115]: \"s\"\n",
            "Token[116]: \"t\"\n",
            "Token[117]: \"i\"\n",
            "Token[118]: \"o\"\n",
            "Token[119]: \"n\"\n",
            "Token[120]: \",\"\n",
            "Token[121]: \" \"\n",
            "Token[122]: \"e\"\n",
            "Token[123]: \"x\"\n",
            "Token[124]: \"c\"\n",
            "Token[125]: \"l\"\n",
            "Token[126]: \"a\"\n",
            "Token[127]: \"m\"\n",
            "Token[128]: \"a\"\n",
            "Token[129]: \"t\"\n",
            "Token[130]: \"i\"\n",
            "Token[131]: \"o\"\n",
            "Token[132]: \"n\"\n",
            "Token[133]: \",\"\n",
            "Token[134]: \" \"\n",
            "Token[135]: \"o\"\n",
            "Token[136]: \"r\"\n",
            "Token[137]: \" \"\n",
            "Token[138]: \"c\"\n",
            "Token[139]: \"o\"\n",
            "Token[140]: \"m\"\n",
            "Token[141]: \"m\"\n",
            "Token[142]: \"a\"\n",
            "Token[143]: \"n\"\n",
            "Token[144]: \"d\"\n",
            "Token[145]: \",\"\n",
            "Token[146]: \" \"\n",
            "Token[147]: \"a\"\n",
            "Token[148]: \"n\"\n",
            "Token[149]: \"d\"\n",
            "Token[150]: \" \"\n",
            "Token[151]: \"c\"\n",
            "Token[152]: \"o\"\n",
            "Token[153]: \"n\"\n",
            "Token[154]: \"s\"\n",
            "Token[155]: \"i\"\n",
            "Token[156]: \"s\"\n",
            "Token[157]: \"t\"\n",
            "Token[158]: \"i\"\n",
            "Token[159]: \"n\"\n",
            "Token[160]: \"g\"\n",
            "Token[161]: \" \"\n",
            "Token[162]: \"o\"\n",
            "Token[163]: \"f\"\n",
            "Token[164]: \" \"\n",
            "Token[165]: \"a\"\n",
            "Token[166]: \" \"\n",
            "Token[167]: \"m\"\n",
            "Token[168]: \"a\"\n",
            "Token[169]: \"i\"\n",
            "Token[170]: \"n\"\n",
            "Token[171]: \" \"\n",
            "Token[172]: \"c\"\n",
            "Token[173]: \"l\"\n",
            "Token[174]: \"a\"\n",
            "Token[175]: \"u\"\n",
            "Token[176]: \"s\"\n",
            "Token[177]: \"e\"\n",
            "Token[178]: \" \"\n",
            "Token[179]: \"a\"\n",
            "Token[180]: \"n\"\n",
            "Token[181]: \"d\"\n",
            "Token[182]: \" \"\n",
            "Token[183]: \"s\"\n",
            "Token[184]: \"o\"\n",
            "Token[185]: \"m\"\n",
            "Token[186]: \"e\"\n",
            "Token[187]: \"t\"\n",
            "Token[188]: \"i\"\n",
            "Token[189]: \"m\"\n",
            "Token[190]: \"e\"\n",
            "Token[191]: \"s\"\n",
            "Token[192]: \" \"\n",
            "Token[193]: \"o\"\n",
            "Token[194]: \"n\"\n",
            "Token[195]: \"e\"\n",
            "Token[196]: \" \"\n",
            "Token[197]: \"o\"\n",
            "Token[198]: \"r\"\n",
            "Token[199]: \" \"\n",
            "Token[200]: \"m\"\n",
            "Token[201]: \"o\"\n",
            "Token[202]: \"r\"\n",
            "Token[203]: \"e\"\n",
            "Token[204]: \" \"\n",
            "Token[205]: \"s\"\n",
            "Token[206]: \"u\"\n",
            "Token[207]: \"b\"\n",
            "Token[208]: \"o\"\n",
            "Token[209]: \"r\"\n",
            "Token[210]: \"d\"\n",
            "Token[211]: \"i\"\n",
            "Token[212]: \"n\"\n",
            "Token[213]: \"a\"\n",
            "Token[214]: \"t\"\n",
            "Token[215]: \"e\"\n",
            "Token[216]: \" \"\n",
            "Token[217]: \"c\"\n",
            "Token[218]: \"l\"\n",
            "Token[219]: \"a\"\n",
            "Token[220]: \"u\"\n",
            "Token[221]: \"s\"\n",
            "Token[222]: \"e\"\n",
            "Token[223]: \"s\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.models import SequenceTagger\n",
        "\n",
        "# make a sentence\n",
        "sentence = Sentence(txt)\n",
        "\n",
        "# load the NER tagger\n",
        "tagger = SequenceTagger.load('ner')\n",
        "\n",
        "# run NER over sentence\n",
        "tagger.predict(sentence)"
      ],
      "metadata": {
        "id": "3lyOcUhs1SqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MY-m7_YD1XeV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}